All right.
Last week an artificial intelligence company opened ai unveiled chatgpt4.
The ai language tool that's frightening people around the wool, gpt4 that can analyze thousands of words and text that can analyze everything, coding, to passing standardized tests and it can even write lawsuits.
Ai technology is developing at a dizzying pace and able to re-create voices as Antonio Sullivan found out and we showed it to you last weekend by using one to simulate his own voice in a phone call with his parents.
>> How are you doing?
>> Hi, dad.
How are you?
>> Good.
Yourself?
>> Just finished shooting our story here.
I'm going to the airport in a while.
>> Oh, you're going back?
>> The plane this weekend.
>> Okay.
Well, it may seem like fun and games.
Ai technology can even be used to create so-called deep fakes.
That's not so funny which are digital masks that can replicate the look of just about anyone like this.
>> If you're a pretty good climber I want to see you climb this.
Not easy to do.
Discipline and hard work.
I don't know what I'm talking about.
It's crazy!
>> Remember that?
That was not Tom Cruise even though it looked like him.
Some are now raising alarms about how these advances could be used to create and spread misinformation.
Our next guest is an ai expert and amerity us professor of psychology and author of rebooting ai, building artificial intelligence we can trust.
Welcome, Dr. Gary Marcus.
Good to see you.
>> Thanks for having me.
Doctor, you know more about this technology than most.
You've even developed your own versions.
So for all of us who are just learning about this whole world of ai, how does it work in its current form and why is it that you are concerned about kind of the next level?
What can happen next?
>> I think the first thing to understand is it's not as intelligence as it looks.
It's mimicking a huge database of things that it's seen before and it is so huge that an ordinary human being probably can't imagine how huge it is and it's billions of texts and what it's doing is it's prestiging them, it's piecing together weird things.
It blamed the silicon valley bank on gpt5 and it didn't exist.
Even though it looks smart it's making stuff up.
>> Maybe it shouldn't be called artificial intelligence, but something else. You wrote an article in "The atlantic." We talked about how bad actors can manipulate the powers of the ai tools to spread misinformation.
I guess, what are the degrees of your worries about this?
Is there going to be a point where it's going to be difficult to differentiate real thing from ai generated if we're not there already?
>> We are very close to that point right now, and part of the concern that bad actors can deliberately use this to miss inform people.
It's one thing to have fun with Tom Cruise and having him say something wacky, but you can imagine troll farms trying to influence our elections and my single biggest fear is that that people will disrupt democracy by making an atmosphere where we can't trust anything.
Where when you look at Twitter and you look at Facebook, you
don't know what's true anymore.
>> Right.
>> The sheer volume that you can make with these machines.
You can make millions and billions of misinformation a day with your own alternative set of facts are and it's plausible and it rz references and data and most humans won't be able to tell the difference and a lot of people can't trust anything.
>> That's my biggest worry.
We just came off of it.
A lot of people are stuck.
They've used the terminology of fake news and then people believe it and then you have this forum, these tools that can help that happen and look more believable and people can't discern the difference between
real and fake.
I feel like we may have run into this jurassic park moment where these ai creators are so preoccupied with whether they could, they didn't stop to think if we really should.
>> I think that's exactly right.
I wrote another essay, the jurassic park moment of ai and quoted that bit.
I quoted Jeff blume and how that accurate is.
In terms of the uses of misinformation and in terms of accidental misinformation around health and ultimately people